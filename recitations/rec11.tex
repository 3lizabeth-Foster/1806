\documentclass{article}
\usepackage{amsmath, amsthm, amssymb, amsfonts, dsfont, fancyhdr, graphicx, color, tabularx, enumitem}
\usepackage{geometry}


\theoremstyle{definition}
\newtheorem{prob}{}
\renewcommand{\qedsymbol}{}
\renewcommand*{\proofname}{Solution}
\newcommand{\MSB}[1]{\textcolor{blue}{[MSB: #1]}}
\def\tr{\text{tr}}

\pagestyle{fancy} \fancyhf{} \lhead{\textsc{18.06}} \rhead{11/29/22} 

\begin{document}


\section*{Practice Problems}
\begin{prob} Remember that a matrix $Q$ is \emph{unitary} if $Q^HQ = I$. A matrix is \emph{orthogonal} if it is real and unitary; that is, if it is real and $Q^TQ=I$.
\begin{itemize}
	\item[a)] Find the flaw in this argument:
	
	 \textbf{False Claim: all eigenvalues of an orthogonal matrix are $\pm 1$.}  Indeed, if $Qx = \lambda x$,
	\[\lambda^2 x^T x = (Qx)^T (Qx) = x^T (Q^T Q) x = x^Tx, \]
	therefore $\lambda^2 = 1$, so $\lambda = \pm 1$. 
	
	 If you're stuck, think about what happens for a rotation matrix
	\[ R = \begin{pmatrix} \cos \theta & -\sin \theta \\ \sin \theta & \cos \theta \end{pmatrix}.\]
	
	\item[b)] Correct the proof to show 
	
	\textbf{True Claim: all eigenvalues of a unitary matrix have magnitude $1$ (e.g. $\lambda = e^{i \phi}$ for some $\phi$).}
	
	\item[c)] Show that the eigenvectors for different eigenvalues of a unitary matrix are orthogonal.
	
	\item[d)] Show that the determinant of any real unitary matrix (e.g., an orthogonal matrix) is $\pm 1$ using eigenvalues.  (Note: you already proved this on a previous pset in a different way.)
	
\end{itemize}
\end{prob}


\begin{prob}
Here is a quick ``proof" that the eigenvalues of \textbf{every} real matrix $A$ are real:
\[\text{\textbf{False Proof: }} Ax = \lambda x \text{ gives } x^TAx = \lambda x^Tx, \quad \text{so } \ \lambda  = \frac{ x^TAx}{x^Tx} = \frac{\text{real}}{\text{real}}.\]
Find the flaw in this reasoning -- a hidden assumption that is not justified.  You can test those steps on the 90${}^\circ$ rotation matrix
\[ A = \begin{pmatrix} 0 & -1 \\  1 & 0 \end{pmatrix}, \qquad \lambda =  i, \ x = \begin{pmatrix} i \\ 1 \end{pmatrix}.\]
\end{prob}



\begin{prob}
\begin{itemize}
	\item[a)] If $S$ is a positive definite matrix, show that $S^{-1}$ is also positive definite.
	\item[b)] If $S$ and $T$ are positive definite, show that their sum $S + T$ is also positive definite.   If $S = A^HA$ and $T = B^HB$ for full-column-rank matrices $A$ and $B$, then can you write down a full column-rank matrix $C$ so that $S +T = C^TC$?
\end{itemize}
\end{prob}


\begin{prob}
	Say $A$ is a $3 \times 3$ real matrix. The matrix $B=A+A^T$ has eigenvalues $\lambda_1=2, \lambda_2=0, \lambda_3=1$, with corresponding eigenvectors $x_1=[1\ 2\ 1]$, $x_2=[-2\ 1\ 0]$ and $x_3=[1 \ 2\ -5]$.
	\begin{itemize}
		\item[a)] What is $e^B$? (It's fine to leave your answer as a product of several matrices, as long as each matrix is written down explicitly)
		\item[b)] Let $C=(I-B)(I+B)^{-1}$. What are the eigenvalues and eigenvectors of $C$?
		\item[c)] Give a good approximation for 
		\[y=C^{100} \begin{pmatrix}
			1\\1\\1
		\end{pmatrix}\]
		in terms of a single eigenvector.
	\end{itemize}
\end{prob}


\end{document}